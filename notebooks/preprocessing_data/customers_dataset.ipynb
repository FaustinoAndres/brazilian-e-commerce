{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customers Dataset\n",
    "Contains an hash to identify the customer and info about his location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Column Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Column Title**|**customer_id -> str** |**customer_unique_id -> str** |**customer_zip_code_prefix -> int** |**customer_city -> str**| **customer_state -> str**|\n",
    "|--|--|--|--|--|--|\n",
    "|Description |Primary key for this table |Customer Identifier Number |Zip Code from Customer Location |City Name from Customer |State Code from Customer |\n",
    "|Example |274fa6071e5e17fe303b9748641082c8 |84732c5050c01db9b23e19ba39899398 |06703 |cotia |SP |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors found\n",
    "+ For this table the raw data didn't contain null or empties values.\n",
    "+ Cities names contains variations and special characters like:\n",
    "    + \"santana do livramento\" / \"sant ana do livramento\"\n",
    "    + \"varre-sai\", \"xique-xique\"\n",
    "    + \"jaragua do sul\" / \"jaragua d sul\" / \"jaragua da sul\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to work with CSV easily.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to create 3 new tables for cities, states, and zipcodes. So it is necessary to replace information in this three columns for his id in the respective table:\n",
    "\n",
    "|External Table | External Column with new id| column to replace|\n",
    "|--|--|--|\n",
    "|code_zip_prefix_dataset |code_zip_prefix_id |customer_zip_code_prefix |\n",
    "|city_state_dataset |city_state_id |customer_city |\n",
    "|state_dataset |state_id |customer_state|\n",
    "\n",
    "Example:\n",
    "\n",
    "For first row the info of this 3 columns is:\n",
    "\n",
    "|customer_zip_code_prefix |customer_city |customer_state |\n",
    "|--|--|--|\n",
    "|14409 |franca |SP |\n",
    "\n",
    "Looking in the external table **state_dataset** we find the id **1** corresponds to state **SP**. So we need to replace **SP** for **1**.\n",
    "\n",
    "|customer_zip_code_prefix |customer_city |customer_state |\n",
    "|--|--|--|\n",
    "|14409 |franca |1 |\n",
    "\n",
    "We make the same process for zipcode. Looking in **code_zip_prefix_dataset** we need to replace **14409** for the new id **5353**.\n",
    "\n",
    "|customer_zip_code_prefix |customer_city |customer_state |\n",
    "|--|--|--|\n",
    "|5353 |franca |1 |\n",
    "\n",
    "City replace process is a little different. Like in Brazil exist cities with same name, we decide to add the state code to city name. Leaving the original **franca** as **franca/SP**.\n",
    "\n",
    "|customer_zip_code_prefix |customer_city |customer_state |\n",
    "|--|--|--|\n",
    "|5353 |franca/SP |1 |\n",
    "\n",
    "After this change we look for the new id in **city_state_dataset**. The corresponding id for **franca/SP** is **1842**. After this change our row is ready. **customer_id** and **customer_unique_id** don't change his value.\n",
    "\n",
    "|customer_zip_code_prefix |customer_city |customer_state |\n",
    "|--|--|--|\n",
    "|5353 |1842 |1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean cities names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete special characters ('-', ',', \"'\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../data/interim/customers_dataset.csv'\n",
    "column_to_replace = 'customer_city'\n",
    "\n",
    "not_valid_char = ['-', ',', \"'\"]\n",
    "\n",
    "def clean(word):\n",
    "    clean_word = ''\n",
    "    for letter in word:\n",
    "        if not(letter in not_valid_char):\n",
    "            clean_word = clean_word + letter\n",
    "    return clean_word\n",
    "\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset[column_to_replace] = dataset[column_to_replace].map(clean)\n",
    "dataset.to_csv('../../data/interim/customers_dataset.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change cities names to city_state format (city/state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change city from \"franca\" to \"franca/SP\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../data/interim/customers_dataset.csv'\n",
    "column_to_replace = 'customer_city'\n",
    "column_state = 'customer_state'\n",
    "\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "print(dataset[column_to_replace][0])\n",
    "for register in range(len(dataset[column_to_replace])):\n",
    "    dataset[column_to_replace][register] = dataset[column_to_replace][register] + '/' + dataset[column_state][register]\n",
    "\n",
    "dataset.to_csv('../../data/interim/customers_dataset.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace city name for his corresponding ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace city name for an id according with **city_state_dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dataset = '../../data/interim/city_state_dataset.csv'\n",
    "replace_id = 'city_state'\n",
    "replace_column = 'city_state_id'\n",
    "\n",
    "dataset_path = '../../data/interim/customers_dataset.csv'\n",
    "column_to_replace = 'customer_city'\n",
    "\n",
    "replace_table = pd.read_csv(replace_dataset)\n",
    "replace_keys = list(replace_table[replace_id])\n",
    "replace_values = list(replace_table[replace_column])\n",
    "replace_dict = dict(zip(replace_keys, replace_values))\n",
    "\n",
    "not_find = []\n",
    "\n",
    "def replace(word):\n",
    "    try:\n",
    "        return replace_dict[word]\n",
    "    except KeyError:\n",
    "        if type(word) is not int:\n",
    "            not_find.append(word)\n",
    "        return word\n",
    "\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset[column_to_replace] = dataset[column_to_replace].map(replace)\n",
    "dataset.to_csv('../../data/interim/customers_dataset.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct small cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take an official list of Brazil cities from wikipedia. But in raw dataset there are some small towns that are consider cities. We search for the closest great city in official list to replace for it. A dict with replacements are in **small_cities_replace**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cities_dict = {name:'' for name in not_find}\n",
    "print(small_cities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "boredtext = open('./bored_dict.txt', 'r+')\n",
    "base = boredtext.read()\n",
    "edit = ''\n",
    "\n",
    "mem = 0\n",
    "for character in base:\n",
    "    if mem == 1:\n",
    "        edit = edit + '\\n'\n",
    "        mem = 0\n",
    "    else:\n",
    "        edit = edit + character\n",
    "\n",
    "    if character == ',':\n",
    "        mem = 1\n",
    "\n",
    "boredtext.write(edit)\n",
    "boredtext.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cities_replace = {'parati/RJ': 'paraty/RJ',\n",
    "    'embu/SP': 'embu das artes/SP',\n",
    "    'bom jesus/GO': 'bom jesus de goias/GO',\n",
    "    'espigao do oeste/RO': 'espigao d oeste/RO',\n",
    "    'passa tres/RJ': 'rio claro/RJ',\n",
    "    'ipiabas/RJ': 'barra do pirai/RJ',\n",
    "    'vitoria/PR': 'porto vitoria/PR',\n",
    "    'nucleo residencial pilar/BA': 'jaguarari/BA',\n",
    "    'taperuaba/CE': 'sobral/CE',\n",
    "    'itaipava/ES': 'itapemirim/ES',\n",
    "    'glaura/MG': 'ouro preto/MG',\n",
    "    'bonfim paulista/SP': 'ribeirao preto/SP',\n",
    "    'vila muriqui/RJ': 'mangaratiba/RJ',\n",
    "    'nossa senhora do remedio/SP': 'salesopolis/SP',\n",
    "    'piumhii/MG': 'piumhi/MG',\n",
    "    'maioba/MA': 'paco do lumiar/MA',\n",
    "    'monnerat/RJ': 'duas barras/RJ',\n",
    "    'desembargador otoni/MG': 'diamantina/MG',\n",
    "    'tocos/RJ': 'campos dos goytacazes/RJ',\n",
    "    'bom jesus do querendo/RJ': 'natividade/RJ',\n",
    "    'rainha do mar/RS': 'xangri la/RS',\n",
    "    'cipo guacu/SP': 'embu guacu/SP',\n",
    "    'taguatinga/DF': 'brasilia/DF',\n",
    "    'santana do sobrado/BA': 'casa nova/BA',\n",
    "    'anta/RJ': 'sapucaia/RJ',\n",
    "    'arraial d ajuda/BA': 'porto seguro/BA',\n",
    "    'sacra familia do tingua/RJ': 'engenheiro paulo de frontin/RJ',\n",
    "    'braco do rio/ES': 'conceicao da barra/ES',\n",
    "    'california da barra/RJ': 'barra do pirai/RJ',\n",
    "    'sao joao de petropolis/ES': 'santa teresa/ES',\n",
    "    'santa isabel do para/PA': 'santa izabel do para/PA',\n",
    "    'vila nova/PR': 'toledo/PR',\n",
    "    'portela/RJ': 'itaocara/RJ',\n",
    "    'caraiba/PE': 'ibimirim/PE',\n",
    "    'vila dos cabanos/PA': 'barcarena/PA',\n",
    "    'arace/ES': 'domingos martins/ES',\n",
    "    'barra do tarrachil/BA': 'chorrocho/BA',\n",
    "    'capao da porteira/RS': 'viamao/RS',\n",
    "    'sao thome das letras/MG': 'sao tome das letras/MG',\n",
    "    'goitacazes/RJ': 'campos dos goytacazes/RJ',\n",
    "    'quilometro 14 do mutum/ES': 'baixo guandu/ES',\n",
    "    'sao francisco do humaita/MG': 'mutum/MG',\n",
    "    'cuite velho/MG': 'conselheiro pena/MG',\n",
    "    'papucaia/RJ': 'cachoeiras de macacu/RJ',\n",
    "    'angelo frechiani/ES': 'colatina/ES',\n",
    "    'praia grande/ES': 'fundao/ES',\n",
    "    'barra de sao joao/RJ': 'casimiro de abreu/RJ',\n",
    "    'arrozal/RJ': 'pirai/RJ',\n",
    "    'santana do livramento/RS': 'sant ana do livramento/RS',\n",
    "    'valao do barro/RJ': 'sao sebastiao do alto/RJ',\n",
    "    'engenheiro passos/RJ': 'resende/RJ',\n",
    "    'primavera/SP': 'rosana/SP',\n",
    "    'conservatoria/RJ': 'valenca/RJ',\n",
    "    'colonia vitoria/PR': 'guarapuava/PR',\n",
    "    'vermelho/MG': 'muriae/MG',\n",
    "    'sobradinho/DF': 'brasilia/DF',\n",
    "    'aparecida de sao manuel/SP': 'sao manuel/SP',\n",
    "    'itapage/CE': 'itapaje/CE',\n",
    "    'catu de abrantes/BA': 'lauro de freitas/BA',\n",
    "    'espigao/SP': 'regente feijo/SP',\n",
    "    'domiciano ribeiro/GO': 'cristalina/GO',\n",
    "    'alto alegre do iguacu/PR': 'capitao leonidas marques/PR',\n",
    "    'itaoca/ES': 'itapemirim/ES',\n",
    "    'macuco de minas/MG': 'itumirim/MG',\n",
    "    'sao jose do turvo/RJ': 'barra do pirai/RJ',\n",
    "    'sao sebastiao de campos/RJ': 'campos dos goytacazes/RJ',\n",
    "    'jacare/SP': 'cabreuva/SP',\n",
    "    'santa cruz do timbo/SC': 'porto uniao/SC',\n",
    "    'araguaia/ES': 'marechal floriano/ES',\n",
    "    'celina/ES': 'alegre/ES',\n",
    "    'pureza/RJ': 'sao fidelis/RJ',\n",
    "    'conrado/RJ': 'miguel pereira/RJ',\n",
    "    'jamapara/RJ': 'sapucaia/RJ',\n",
    "    'jamaica/SP': 'praia grande/SP',\n",
    "    'arembepe/BA': 'camacari/BA',\n",
    "    'santa cruz do prata/MG': 'guaranesia/MG',\n",
    "    'glicerio/RJ': 'macae/RJ',\n",
    "    'sao jorge do oeste/PR': 'curitiba/PR',\n",
    "    'cocais/MG': 'barao de cocais/MG',\n",
    "    'bemposta/RJ': 'tres rios/RJ',\n",
    "    'raposo/RJ': 'itaperuna/RJ',\n",
    "    'japuiba/RJ': 'angra dos reis/RJ',\n",
    "    'hidreletrica tucurui/PA': 'tucurui/PA',\n",
    "    'palmeirinha/PR': 'guarapuava/PR',\n",
    "    'luizlandia do oeste/MG': 'sao goncalo do abaete/MG',\n",
    "    'cachoeira do campo/MG': 'ouro preto/MG',\n",
    "    'santo amaro de campos/RJ': 'campos dos goytacazes/RJ',\n",
    "    'santa rita do ibitipoca/MG': 'santa rita de ibitipoca/MG',\n",
    "    'polo petroquimico de triunfo/RS': 'triunfo/RS',\n",
    "    'bataipora/MS': 'bataypora/MS',\n",
    "    'extrema/RO': 'porto velho/RO',\n",
    "    'werneck/RJ': 'paraiba do sul/RJ',\n",
    "    'irape/SP': 'chavantes/SP',\n",
    "    'antonio pereira/MG': 'ouro preto/MG',\n",
    "    'vargem alegre/RJ': 'barra do pirai/RJ',\n",
    "    'serra dos dourados/PR': 'umuarama/PR',\n",
    "    'avelar/RJ': 'paty do alferes/RJ',\n",
    "    'sao joao do paraiso/RJ': 'cambuci/RJ',\n",
    "    'quatro bocas/PA': 'nova timboteua/PA',\n",
    "    'guara/DF': 'brasilia/DF',\n",
    "    'porto trombetas/PA': 'oriximina/PA',\n",
    "    'sao mateus de minas/MG': 'camanducaia/MG',\n",
    "    'santo antonio dos campos/MG': 'divinopolis/MG',\n",
    "    'travessao/RJ': 'campos dos goytacazes/RJ',\n",
    "    'santa margarida/PR': 'bela vista do paraiso/PR',\n",
    "    'queixada/MG': 'novo cruzeiro/MG',\n",
    "    'barao de juparana/RJ': 'valenca/RJ',\n",
    "    'silveira carvalho/MG': 'barao de monte alto/MG',\n",
    "    'trancoso/BA': 'porto seguro/BA',\n",
    "    'couto de magalhaes/TO': 'couto magalhaes/TO',\n",
    "    'lidice/RJ': 'rio claro/RJ',\n",
    "    'itamira/BA': 'apora/BA',\n",
    "    'santanesia/RJ': 'pirai/RJ',\n",
    "    'nossa senhora de caravaggio/SC': 'nova veneza/SC',\n",
    "    'ibiraja/BA': 'itanhem/BA',\n",
    "    'abrantes/BA': 'lauro de freitas/BA',\n",
    "    'sao goncalo do rio das pedras/MG': 'serro/MG',\n",
    "    'florinia/SP': 'florinea/SP',\n",
    "    'azurita/MG': 'mateus leme/MG',\n",
    "    'andrequice/MG': 'tres marias/MG',\n",
    "    'nossa senhora do o/PE': 'ipojuca/PE',\n",
    "    'purilandia/RJ': 'porciuncula/RJ',\n",
    "    'morro vermelho/MG': 'caete/MG',\n",
    "    'santa rita da floresta/RJ': 'cantagalo/RJ',\n",
    "    'morro do ferro/MG': 'oliveira/MG',\n",
    "    'sao benedito/MG': 'santa luzia/MG',\n",
    "    'vila nelita/ES': 'agua doce do norte/ES',\n",
    "    'osvaldo kroeff/RS': 'cambara do sul/RS',\n",
    "    'rio verde/PR': 'colombo/PR',\n",
    "    'morro de sao paulo/BA': 'cairu/BA',\n",
    "    'holambra ii/SP': 'holambra/SP',\n",
    "    'areia branca dos assis/PR': 'mandirituba/PR',\n",
    "    'conceicao da ibitipoca/MG': 'lima duarte/MG',\n",
    "    'morada nova/PA': 'maraba/PA',\n",
    "    'sao joao do sobrado/ES': 'pinheiros/ES',\n",
    "    'monte verde/MG': 'camanducaia/MG',\n",
    "    'pocoes de paineiras/MG': 'paineiras/MG',\n",
    "    'maracana/SC': 'palhoca/SC',\n",
    "    'sao vitor/MG': 'belo horizonte/MG',\n",
    "    'ravena/MG': 'sabara/MG',\n",
    "    'sao luis do paraitinga/SP': 'sao luiz do paraitinga/SP',\n",
    "    'sao sebastiao da serra/SP': 'brotas/SP',\n",
    "    'mussurepe/RJ': 'campos dos goytacazes/RJ',\n",
    "    'cambiasca/RJ': 'sao fidelis/RJ',\n",
    "    'caldas do jorro/BA': 'feira de santana/BA',\n",
    "    'aguas claras/RS': 'viamao/RS',\n",
    "    'santana/PR': 'candoi/PR',\n",
    "    'monte gordo/BA': 'camacari/BA',\n",
    "    'santa maria/RJ': 'santa maria madalena/RJ',\n",
    "    'jacigua/ES': 'vargem alta/ES',\n",
    "    'antunes/MG': 'igaratinga/MG',\n",
    "    'boa esperanca/RJ': 'rio bonito/RJ',\n",
    "    'bandeirantes d oeste/SP': 'sud mennucci/SP',\n",
    "    'santo antonio das queimadas/PE': 'jurema/PE',\n",
    "    'perpetuo socorro/MG': 'belo oriente/MG',\n",
    "    'estevao de araujo/MG': 'araponga/MG',\n",
    "    'luziapolis/AL': 'campo alegre/AL',\n",
    "    'quixada/PE': 'quixaba/PE',\n",
    "    'pirapo/PR': 'arapongas/PR',\n",
    "    'aribice/BA': 'euclides da cunha/BA',\n",
    "    'doce grande/PR': 'quitandinha/PR',\n",
    "    'piacu/ES': 'muniz freire/ES',\n",
    "    'maristela/SP': 'laranjal paulista/SP',\n",
    "    'alto alegre/PR': 'cascavel/PR',\n",
    "    'fragosos/SC': 'campo alegre/SC',\n",
    "    'colonia jordaozinho/PR': 'guarapuava/PR',\n",
    "    'missi/CE': 'iraucuba/CE',\n",
    "    'murucupi/PA': 'barcarena/PA',\n",
    "    'lagoa do mato/CE': 'itatira/CE',\n",
    "    'quatituba/MG': 'itueta/MG',\n",
    "    'campo alegre de minas/MG': 'resplendor/MG',\n",
    "    'sao domingos/MG': 'uba/MG',\n",
    "    'engenheiro balduino/SP': 'monte aprazivel/SP',\n",
    "    'agisse/SP': 'rancharia/SP',\n",
    "    'alexandrita/MG': 'iturama/MG',\n",
    "    'perola independente/PR': 'maripa/PR',\n",
    "    'tecainda/SP': 'martinopolis/SP',\n",
    "    'central de santa helena/MG': 'divino das laranjeiras/MG',\n",
    "    'tuparece/MG': 'medina/MG',\n",
    "    'aparecida de monte alto/SP': 'monte alto/SP',\n",
    "    'sao geraldo do baguari/MG': 'sao joao evangelista/MG',\n",
    "    'sao domingos/PE': 'brejo da madre de deus/PE',\n",
    "    'botelho/SP': 'santa adelia/SP',\n",
    "    'padre gonzales/RS': 'tres passos/RS',\n",
    "    'taboquinhas/BA': 'itacare/BA',\n",
    "    'ceilandia/DF': 'brasilia/DF',\n",
    "    'visconde de maua/RJ': 'resende/RJ',\n",
    "    'governador portela/RJ': 'miguel pereira/RJ',\n",
    "    'humildes/BA': 'feira de santana/BA',\n",
    "    'ibitioca/RJ': 'campos dos goytacazes/RJ',\n",
    "    'alto sao joao/PR': 'laranjeiras do sul/PR',\n",
    "    'chaveslandia/MG': 'santa vitoria/MG',\n",
    "    'carajas/PA': 'parauapebas/PA',\n",
    "    'brejo bonito/MG': 'cruzeiro da fortaleza/MG',\n",
    "    'itaguacu/GO': 'sao simao/GO',\n",
    "    'colonia castrolanda/PR': 'castro/PR',\n",
    "    'amanari/CE': 'maranguape/CE',\n",
    "    'jaguarembe/RJ': 'itaocara/RJ',\n",
    "    'santana do capivari/MG': 'pouso alto/MG',\n",
    "    'novo brasil/ES': 'cariacica/ES',\n",
    "    'ribeiro junqueira/MG': 'leopoldina/MG',\n",
    "    'cachoeira do brumado/MG': 'mariana/MG',\n",
    "    'pau d arco/AL': 'lagoa da canoa/AL',\n",
    "    'posto da mata/BA': 'nova vicosa/BA',\n",
    "    'carnaiba do sertao/BA': 'juazeiro/BA',\n",
    "    'sapucaia/MG': 'caratinga/MG',\n",
    "    'ibiajara/BA': 'rio do pires/BA',\n",
    "    'ponto do marambaia/MG': 'carai/MG',\n",
    "    'rechan/SP': 'itapetininga/SP',\n",
    "    'salobro/BA': 'canarana/BA',\n",
    "    'santa maria/DF': 'brasilia/DF',\n",
    "    'guarapua/SP': 'dois corregos/SP',\n",
    "    'piao/RJ': 'sao jose do vale do rio preto/RJ',\n",
    "    'flores/CE': 'russas/CE',\n",
    "    'santo eduardo/RJ': 'campos dos goytacazes/RJ',\n",
    "    'alexandra/PR': 'paranagua/PR',\n",
    "    'paraju/ES': 'domingos martins/ES',\n",
    "    'jacuipe/BA': 'camacari/BA',\n",
    "    'tres irmaos/RJ': 'cambuci/RJ',\n",
    "    'ipiranga/RS': 'viamao/RS',\n",
    "    'boa ventura/RJ': 'itaperuna/RJ',\n",
    "    'angustura/MG': 'alem paraiba/MG',\n",
    "    'martinesia/MG': 'uberlandia/MG',\n",
    "    'prudencio thomaz/MS': 'rio brilhante/MS',\n",
    "    'major porto/MG': 'patos de minas/MG',\n",
    "    'conceicao do formoso/MG': 'santos dumont/MG',\n",
    "    'silvano/MG': 'patrocinio/MG',\n",
    "    'fonseca/MG': 'alvinopolis/MG',\n",
    "    'santo antonio do canaa/ES': 'santa teresa/ES',\n",
    "    'anhandui/MS': 'campo grande/MS',\n",
    "    'guinda/MG': 'diamantina/MG',\n",
    "    'lages/CE': 'maranguape/CE',\n",
    "    'amparo da serra/MG': 'amparo do serra/MG',\n",
    "    'poco de pedra/RN': 'sao goncalo do amarante/RN',\n",
    "    'sao clemente/PR': 'santa helena/PR',\n",
    "    'pinhotiba/MG': 'eugenopolis/MG',\n",
    "    'guassusse/CE': 'oros/CE',\n",
    "    'monte alverne/RS': 'santa cruz do sul/RS',\n",
    "    'ibitira/BA': 'rio do antonio/BA',\n",
    "    'sao jose do ribeirao/RJ': 'bom jardim/RJ',\n",
    "    'vargem grande do soturno/ES': 'cachoeiro de itapemirim/ES',\n",
    "    'vila pereira/MG': 'nanuque/MG',\n",
    "    'bacaxa/RJ': 'saquarema/RJ',\n",
    "    'sucesso/CE': 'tamboril/CE',\n",
    "    'barao ataliba nogueira/SP': 'itapira/SP',\n",
    "    'santa teresinha/BA': 'santa terezinha/BA',\n",
    "    'ajapi/SP': 'rio claro/SP',\n",
    "    'guariroba/SP': 'taquaritinga/SP',\n",
    "    'itabatan/BA': 'mucuri/BA',\n",
    "    'baguari/MG': 'governador valadares/MG',\n",
    "    'sede alvorada/PR': 'cascavel/PR',\n",
    "    'jaua/BA': 'camacari/BA',\n",
    "    'mariental/PR': 'lapa/PR',\n",
    "    'pedra menina/MG': 'espera feliz/MG',\n",
    "    'ibitiuva/SP': 'pitangueiras/SP',\n",
    "    'tapinas/SP': 'itapolis/SP',\n",
    "    'planaltina de goias/GO': 'planaltina/GO',\n",
    "    'graccho cardoso/SE': 'gracho cardoso/SE',\n",
    "    'ilha dos valadares/PR': 'paranagua/PR',\n",
    "    'penedo/RJ': 'itatiaia/RJ',\n",
    "    'mutum parana/RO': 'porto velho/RO',\n",
    "    'picarras/SC': 'penha/SC',\n",
    "    'sao miguel do cambui/PR': 'marialva/PR',\n",
    "    'vitorinos/MG': 'alto rio doce/MG',\n",
    "    'brasopolis/MG': 'brazopolis/MG',\n",
    "    'corrego do ouro/RJ': 'macae/RJ',\n",
    "    'pitanga de estrada/PB': 'mamanguape/PB',\n",
    "    'termas de ibira/SP': 'ibira/SP',\n",
    "    'vila reis/PR': 'apucarana/PR',\n",
    "    'itacurussa/RJ': 'mangaratiba/RJ',\n",
    "    'palmital de minas/MG': 'cabeceira grande/MG',\n",
    "    'jardim abc de goias/GO': 'cidade ocidental/GO',\n",
    "    'dourado/CE': 'morada nova/CE',\n",
    "    'santa isabel do rio preto/RJ': 'valenca/RJ',\n",
    "    'pinheiros/SP': 'sao paulo/SP',\n",
    "    'mendonca/MG': 'veredinha/MG',\n",
    "    'adhemar de barros/PR': 'terra rica/PR',\n",
    "    'sao sebastiao do paraiba/RJ': 'cantagalo/RJ',\n",
    "    'pacotuba/ES': 'itapemirim/ES',\n",
    "    'serra bonita/MG': 'buritis/MG',\n",
    "    'venda branca/SP': 'casa branca/SP',\n",
    "    'sanga puita/MS': 'ponta pora/MS',\n",
    "    'siriji/PE': 'sao vicente ferrer/PE',\n",
    "    'monte bonito/RS': 'pelotas/RS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../data/interim/customers_dataset.csv'\n",
    "column_to_replace = 'customer_city'\n",
    "\n",
    "not_find = []\n",
    "\n",
    "def replace(word):\n",
    "    try:\n",
    "        return small_cities_replace[word]\n",
    "    except KeyError:\n",
    "        if type(word) is not int:\n",
    "            not_find.append(word)\n",
    "        return word\n",
    "\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset[column_to_replace] = dataset[column_to_replace].map(replace)\n",
    "dataset.to_csv('../../data/interim/customers_dataset.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute again \"Replace city name for his corresponding ID\" with the corrected names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace state for his ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace state name for his corresponding id in **state_dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dataset = '../../data/interim/state_dataset.csv'\n",
    "replace_id = 'state'\n",
    "replace_column = 'state_id'\n",
    "\n",
    "dataset_path = '../../data/interim/customers_dataset.csv'\n",
    "column_to_replace = 'customer_state'\n",
    "\n",
    "replace_table = pd.read_csv(replace_dataset)\n",
    "replace_keys = list(replace_table[replace_id])\n",
    "replace_values = list(replace_table[replace_column])\n",
    "replace_dict = dict(zip(replace_keys, replace_values))\n",
    "\n",
    "not_find = []\n",
    "\n",
    "def replace(word):\n",
    "    try:\n",
    "        return replace_dict[word]\n",
    "    except KeyError:\n",
    "        if type(word) is not int:\n",
    "            not_find.append(word)\n",
    "        return word\n",
    "\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset[column_to_replace] = dataset[column_to_replace].map(replace)\n",
    "dataset.to_csv('../../data/interim/customers_dataset.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration to replace zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to find if there are some zipcodes who arent in the **code_zip_prefix_dataset**. And yes there are some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14994\n",
      "19022\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('../../data/interim/customers_dataset.csv')\n",
    "zipcode = pd.read_csv('../../data/interim/code_zip_prefix_dataset.csv')\n",
    "print(len(set(dataset['customer_zip_code_prefix']) ))\n",
    "print(len(set(zipcode['code_zip_prefix']) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the zipcodes with his correct id in **code_zip_prefix_dataset**. Also make a list named **not_find** of zipcodes who aren't in de dataset. So we add them to **code_zip_prefix_dataset** with a sequential id and after replace them in **customers_dataset** to finish this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dataset = '../../data/interim/code_zip_prefix_dataset.csv'\n",
    "replace_id = 'code_zip_prefix'\n",
    "replace_column = 'code_zip_prefix_id'\n",
    "\n",
    "dataset_path = '../../data/interim/customers_dataset.csv'\n",
    "column_to_replace = 'customer_zip_code_prefix'\n",
    "\n",
    "replace_table = pd.read_csv(replace_dataset)\n",
    "replace_keys = list(replace_table[replace_id])\n",
    "replace_values = list(replace_table[replace_column])\n",
    "replace_dict = dict(zip(replace_keys, replace_values))\n",
    "\n",
    "not_find = []\n",
    "\n",
    "def replace(word):\n",
    "    try:\n",
    "        return replace_dict[word]\n",
    "    except KeyError:\n",
    "        not_find.append(word)\n",
    "        return word\n",
    "\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset[column_to_replace] = dataset[column_to_replace].map(replace)\n",
    "dataset.to_csv('../../data/interim/customers_dataset.csv', encoding='utf-8', index=False)\n",
    "\n",
    "#Take care with this part, only use when you have identified the zipcodes who aren't in the code_zip_prefix_dataset. Or it will confuse ID with zipcode and can ruin de dataset.\n",
    "# to add unfinded zipcodes\n",
    "# zipcode = pd.read_csv(replace_dataset)\n",
    "# id_counter = 19023\n",
    "# for element in not_find:\n",
    "#     zipcode.loc[id_counter] = [id_counter, element]\n",
    "#     id_counter += 1\n",
    "# zipcode.to_csv('../../data/interim/code_zip_prefix_dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you saved the dataset always mark **\"index = False\"**. Or pandas will add a new column with a consequtive number. This small script is to remove this useless column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../data/interim/order_reviews_dataset.csv')\n",
    "del(dataset['Unnamed: 0'])\n",
    "print(dataset)\n",
    "dataset.to_csv('../../data/interim/order_reviews_dataset.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Column Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Column Title**|**customer_id -> str** |**customer_unique_id -> str** |**customer_zip_code_prefix -> int** |**customer_city -> int**| **customer_state -> int**|\n",
    "|--|--|--|--|--|--|\n",
    "|Description |Primary key for this table |Customer Identifier Number |code_zip_prefix_id from code_zip_prefix_dataset |city_state_id from city_state_dataset |state_id from state_dataset |\n",
    "|Before Preprocessing |274fa6071e5e17fe303b9748641082c8 |84732c5050c01db9b23e19ba39899398 |06703 |cotia |SP |\n",
    "|After Preprocessing |274fa6071e5e17fe303b9748641082c8 |84732c5050c01db9b23e19ba39899398 |3354 |1437 |1 |"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00a232b2b7d865da3e1b26f8f1ff7b6180ae5c6fb71f3d40d7ab2842faa2993a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
